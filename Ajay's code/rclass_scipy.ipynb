{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"####  üçÅCheck Versions","metadata":{}},{"cell_type":"code","source":"# !python --version\nimport cupy as cp\ncp.__version__","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T23:13:06.122682Z","iopub.execute_input":"2025-01-07T23:13:06.123253Z","iopub.status.idle":"2025-01-07T23:13:06.129195Z","shell.execute_reply.started":"2025-01-07T23:13:06.123217Z","shell.execute_reply":"2025-01-07T23:13:06.128365Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"'13.3.0'"},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","source":"#### üçÅ Create Directory","metadata":{}},{"cell_type":"code","source":"import os\n\nmodels_dir = \"/kaggle/working/models/\"\n\n# Ensure the directory exists\nos.makedirs(models_dir, exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T23:13:06.131865Z","iopub.execute_input":"2025-01-07T23:13:06.132116Z","iopub.status.idle":"2025-01-07T23:13:06.139838Z","shell.execute_reply.started":"2025-01-07T23:13:06.132092Z","shell.execute_reply":"2025-01-07T23:13:06.139155Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"### üçÅ Preprocessing","metadata":{}},{"cell_type":"code","source":"# Import\nfrom keras.datasets import mnist\n(x_train, y_train), (_, _) = mnist.load_data()\nprint(f\"x_train shape: {x_train.shape}, y_train shape: {y_train.shape}\")\n\n#1 Flatten\nx_train_flat = x_train.reshape(x_train.shape[0], -1)\nprint(f\"x_train_flat shape: {x_train_flat.shape}, y_train shape: {y_train.shape}\")\n\n#2 Subsets\nsubset_size = 1000\nx_train_subset = x_train_flat[:subset_size]\ny_train_subset = y_train[:subset_size]\nprint(f\"x_train_subset shape: {x_train_subset.shape}\")\n\n#3 PCA\nfrom sklearn.decomposition import PCA\n# import pickle\nimport numpy as np\nn_components = 77\npca = PCA(n_components=n_components)\nx_train_pca = pca.fit_transform(x_train_subset)\nprint(f\"x_train_pca shape: \", x_train_pca.shape)\nvariance = np.sum(pca.explained_variance_ratio_)\nprint(f\"variance =\", variance)\n\n#4 Normalize\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler(feature_range=(0, 1))\nx_train_norm = scaler.fit_transform(x_train_pca)\nprint(f\"x_train_norm shape: {x_train_norm.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T23:13:06.145925Z","iopub.execute_input":"2025-01-07T23:13:06.146180Z","iopub.status.idle":"2025-01-07T23:13:07.174475Z","shell.execute_reply.started":"2025-01-07T23:13:06.146156Z","shell.execute_reply":"2025-01-07T23:13:07.173358Z"}},"outputs":[{"name":"stdout","text":"x_train shape: (60000, 28, 28), y_train shape: (60000,)\nx_train_flat shape: (60000, 784), y_train shape: (60000,)\nx_train_subset shape: (1000, 784)\nx_train_pca shape:  (1000, 77)\nvariance = 0.9022627966098498\nx_train_norm shape: (1000, 77)\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"### [Training]","metadata":{}},{"cell_type":"code","source":"import pickle\nimport cupy as cp\nimport numpy as np\nfrom scipy.optimize import linprog\nimport matplotlib.pyplot as plt\nimport itertools\n\n# Feasibility check function\ndef check_feasibility_and_compute_coefficients(z, x_train_norm, y_binary):\n    num_data_points = x_train_norm.shape[0]\n    num_coefficients = n_components + 1  # (+1 for the first constant terms Œ±0 & Œ≤0)\n    delta = 1e-6  # a small positive value\n\n    # Construct G(x) and H(x) matrices for numerator and denominator\n    G = cp.zeros((num_data_points, num_coefficients))  # Numerator matrix\n    H = cp.zeros((num_data_points, num_coefficients))  # Denominator matrix\n\n    for i in range(num_data_points):\n      G[i, 0] = 1\n      H[i, 0] = 1\n      for j in range(num_coefficients-1):\n        G[i, j+1] = x_train_norm[i, j] ** (j+1)\n        H[i, j+1] = x_train_norm[i, j] ** (j+1)\n\n    # print(f\"G: {G}\")\n    # print(f\"G.shape =\", G.shape)\n    # print(f\"H: {H}\")\n\n    #-----------------------------------------\n    # def construct_G_H_matrices(x_train_norm, n, d):\n    #   import itertools\n    #   num_data_points = x_train_norm.shape[0]\n    \n    #   # Generate multi-indices\n    #   multi_indices = [idx for idx in itertools.product(range(d + 1), repeat=n) if sum(idx) <= d]\n    #   num_coefficients = len(multi_indices)\n    \n    #   # Initialize G and H matrices\n    #   G = cp.zeros((num_data_points, num_coefficients))  # Numerator\n    #   H = cp.zeros((num_data_points, num_coefficients))  # Denominator\n    \n    #   # Construct G and H using multi-indices\n    #   for i in range(num_data_points):\n    #       for j, idx in enumerate(multi_indices):\n    #           term = cp.prod(cp.array([x_train_norm[i, k] ** idx[k] for k in range(n)]))\n    #           G[i, j] = term\n    #           H[i, j] = term  # G and H share the same multi-index logic\n    #   return G, H, multi_indices\n    \n    # def generate_multi_indices(n, d):\n    #     indices = [idx for idx in itertools.product(range(d + 1), repeat=n) if sum(idx) <= d]\n    #     return indices\n\n    # num_data_points = x_train_norm.shape[0]\n    # indices = generate_multi_indices(2, 2)\n    \n    # num_coefficients = len(indices)\n    \n    # G, H, multi_indices = construct_G_H_matrices(x_train_norm, 2, 2)\n    \n    # Construct constraints for Ax <= b\n    A = []\n    b = []\n\n    for i in range(num_data_points):\n        f_plus_z = y_binary[i] + z  # Upper bound\n        f_minus_z = y_binary[i] - z  # Lower bound\n\n        # Constraint 1: (f(xi) - z) * Œ≤^T H(xi) - Œ±^T G(xi) ‚â§ Œ∏\n        # (-G(xi))Œ±T + (f(xi) - z).H(xi)Œ≤T + (-1)Œ∏ ‚â§ 0\n        constraint_1 = cp.zeros(2 * num_coefficients + 1)\n        # (1) Coefficients of Œ±\n        constraint_1[0:num_coefficients] = -G[i]\n        # (2) Coefficients of Œ≤\n        constraint_1[num_coefficients:2 * num_coefficients] = (f_minus_z) * H[i]\n        # (3) Coefficient of Œ∏ (last element)\n        constraint_1[-1] = -1\n        A.append(constraint_1)\n        b.append(0)\n\n        # Constraint 2: Œ±^T G(xi) + (-1).(f(xi) + z) * Œ≤^T H(xi) ‚â§ Œ∏\n        # G(xi).Œ±T + (-1)(f(xi) - z).H(xi)Œ≤T + (-1)Œ∏ ‚â§ 0\n        constraint_2 = cp.zeros(2 * num_coefficients + 1)\n        # (1) Coefficients of Œ±\n        constraint_2[0:num_coefficients] = G[i]\n        # (2) Coefficients of Œ≤\n        constraint_2[num_coefficients:2 * num_coefficients] = -(f_plus_z) * H[i]\n        # (3) Coefficient of Œ∏ (last element)\n        constraint_2[-1] = -1\n        A.append(constraint_2)\n        b.append(0)\n\n        # Constraint 3: Œ≤^T H(x) ‚â• Œ¥\n        # (0)Œ±^T + (-H(x)) Œ≤^T + (0)Œ∏ ‚â§ -Œ¥\n        constraint_3 = cp.zeros(2 * num_coefficients + 1)\n        # Coefficient of Œ≤\n        constraint_3[num_coefficients:2 * num_coefficients] = -H[i]\n        A.append(constraint_3)\n        b.append(-delta)\n\n    # Convert CuPy arrays to NumPy arrays for SciPy\n    A = cp.asnumpy(cp.array(A))\n    b = cp.asnumpy(cp.array(b))\n\n    # Objective function to minimize Œ∏\n    c = cp.asnumpy(cp.zeros(2 * num_coefficients + 1))\n    c[-1] = 1  # Only Œ∏ has a coefficient in the objective function\n\n    # Solve the linear programming problem (methods: highs, revised simplex)\n    result = linprog(c, A_ub=A, b_ub=b, method=\"highs\")\n\n    # Check feasibility and return results\n    if result.success:\n        alpha_coefficients = result.x[:num_coefficients]\n        beta_coefficients = result.x[num_coefficients:2 * num_coefficients]\n        theta = result.x[-1]\n        return True, alpha_coefficients, beta_coefficients, theta\n    else:\n        return False, None, None, None\n\n\n# Bisection loop\ndef bisection_loop(x_train_norm, y_binary, uL, uH, precision):\n    optimal_alpha, optimal_beta, optimal_theta = None, None, None\n    z_values = []\n\n    while uH - uL > precision:\n        z = (uL + uH) / 2\n        z_values.append(z)\n        feasible, alpha_coefficients, beta_coefficients, theta = check_feasibility_and_compute_coefficients(z, x_train_norm, y_binary)\n\n        if feasible:\n            uH = z\n            optimal_alpha, optimal_beta, optimal_theta = alpha_coefficients, beta_coefficients, theta\n        else:\n            uL = z\n\n    return uH, optimal_alpha, optimal_beta, optimal_theta, z_values\n\n# Train a classifier for each digit\nfor digit in range(10):\n    print(f\"Training classifier for digit {digit}...\")\n\n    # Assign labels: Positive for the current digit, negative for others\n    # y_binary = (y_train_subset == digit).astype(int)\n    y_binary = (y_train_subset == digit).astype(float)\n\n    # Scale binary labels to larger values\n    # Positive class = 2, Negative class = 4\n    y_binary = np.where(y_binary == 1, 2, 4)\n\n    # print(f\"y_binary =\", y_binary)\n    # print(f\"y_train_subset =\", y_train_subset)\n\n    # Bisection parameters\n    uL = 0  # Initial lower bound\n    uH = 500  # Initial upper bound\n    precision = 1e-6 # Precision threshold\n\n    # Run bisection loop\n    optimal_z, optimal_alpha, optimal_beta, optimal_theta, z_values = bisection_loop(x_train_norm, y_binary, uL, uH, precision)\n\n    # Print results\n    print(f\"Number of Iterations: {len(z_values)}\")\n    # print(f\"z Values in all Iterations: {z_values}\")\n    print(f\"Optimal z (Maximum Deviation): {optimal_z}\")\n\n    # # Plot convergence of z values\n    # plt.figure(figsize=(8, 6))\n    # plt.plot(range(len(z_values)), z_values, marker='o', linestyle='-')\n    # plt.xlabel(\"Iteration\")\n    # plt.ylabel(\"z Value\")\n    # plt.title(\"Convergence of z Values\")\n    # plt.grid(True)\n    # plt.show()\n\n    print(f\"Optimized Coefficients (Numerator Œ±): {optimal_alpha}\")\n    print(f\"Optimized Coefficients (Denominator Œ≤): {optimal_beta}\")\n    print(f\"Optimal Œ∏: {optimal_theta}\")\n    \n    # print(f\"rational_function =\", rational_function(x_train_norm[0], optimal_alpha, optimal_beta))\n\n    # Save the model\n    model = {\n        \"alpha\": optimal_alpha,\n        \"beta\": optimal_beta,\n        \"theta\": optimal_theta,\n        \"n_components\": n_components\n    }\n\n    with open(f\"{models_dir}classifier_{digit}.pkl\", \"wb\") as file:\n        pickle.dump(model, file)\n\n    print(f\"Model for digit {digit} saved at {models_dir}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T23:13:07.176976Z","iopub.execute_input":"2025-01-07T23:13:07.182614Z","iopub.status.idle":"2025-01-07T23:25:14.106489Z","shell.execute_reply.started":"2025-01-07T23:13:07.182555Z","shell.execute_reply":"2025-01-07T23:25:14.105568Z"}},"outputs":[{"name":"stdout","text":"Training classifier for digit 0...\nNumber of Iterations: 29\nOptimal z (Maximum Deviation): 9.313225746154785e-07\nOptimized Coefficients (Numerator Œ±): [ 2.99999772e-06  0.00000000e+00 -1.40324098e-13  2.95590019e-11\n -2.28790100e-11  3.11251392e-11 -3.06229559e-12  1.48115917e-12\n -3.92615656e-12 -2.23383977e-10 -1.06270315e-09  1.56583634e-10\n  3.50400442e-10  2.46807177e-10  4.28925363e-11 -4.24774480e-09\n -1.47996863e-09 -1.04377329e-08 -1.66955686e-09 -3.49228260e-08\n -5.26704233e-10  9.23853579e-12  6.34420314e-10  1.31885970e-10\n  0.00000000e+00  0.00000000e+00  2.35138684e-09 -7.70323226e-09\n  1.99997846e-06  0.00000000e+00  0.00000000e+00  3.18831244e-11\n -5.85008686e-10  3.61616860e-10  0.00000000e+00 -2.37513443e-08\n  1.97675245e-06  1.78256198e-08  0.00000000e+00 -5.97935522e-10\n  0.00000000e+00  6.93516536e-07  2.00282907e-06  9.40787601e-09\n  2.00167748e-06  0.00000000e+00  0.00000000e+00 -7.06838155e-11\n -5.18393052e-08 -8.21029620e-09 -2.79289053e-10  1.41851997e-12\n  2.02104087e-06  5.77668687e-08  5.41637929e-06  0.00000000e+00\n  0.00000000e+00  1.99984458e-06  4.85720297e-08  4.44532817e-05\n  1.99765190e-06 -8.36030126e-09 -2.58273846e-08  0.00000000e+00\n  0.00000000e+00  0.00000000e+00  0.00000000e+00  1.07932911e-09\n  0.00000000e+00  2.00010425e-06  0.00000000e+00  0.00000000e+00\n  8.69821344e-08  2.02236312e-06  0.00000000e+00  0.00000000e+00\n  2.00001183e-06  8.27647508e-09]\nOptimized Coefficients (Denominator Œ≤): [ 9.99998920e-07  8.81140243e-13 -1.26629488e-13  7.96152532e-12\n -5.74147894e-12  6.33441131e-12  1.30840044e-12  5.99782140e-13\n  7.58330818e-12 -9.01042826e-11 -5.80759407e-10  3.41583489e-11\n  4.63745670e-11  6.94697949e-11  0.00000000e+00 -6.99712349e-10\n -3.67060833e-10 -1.98565302e-09  3.29483669e-11 -1.73615554e-08\n -1.24859746e-10  5.02271357e-12  1.60592267e-10  3.82222884e-10\n -8.42231852e-11  9.21863339e-09  4.33359049e-10 -1.97804018e-09\n  0.00000000e+00  3.13657073e-11  2.27663633e-08  6.31092703e-11\n -3.36002397e-10  1.88691762e-10  8.86003823e-09 -6.31164223e-09\n  7.27898784e-12  8.11293904e-09  1.06234874e-05 -6.87256804e-11\n  4.50640350e-09  1.73380084e-07  4.28204103e-10  6.12597703e-11\n -1.86245162e-10  9.74173004e-09  1.78107578e-09 -2.31845553e-11\n -1.29581680e-08  1.56854314e-09 -6.84004944e-11  0.00000000e+00\n  5.29766918e-09  2.88860685e-08  8.54109123e-07 -7.68453125e-12\n  2.19887379e-09  0.00000000e+00  2.42817767e-08  0.00000000e+00\n -4.34616277e-10 -4.16302163e-09 -1.78015923e-10  5.19519187e-13\n -0.00000000e+00 -2.54410563e-10 -2.94000154e-14  0.00000000e+00\n -9.97451593e-11  0.00000000e+00  0.00000000e+00  0.00000000e+00\n  4.34975451e-08  0.00000000e+00 -0.00000000e+00  0.00000000e+00\n  0.00000000e+00  4.16433901e-09]\nOptimal Œ∏: 9.999988859591702e-07\nModel for digit 0 saved at /kaggle/working/models/\nTraining classifier for digit 1...\nNumber of Iterations: 29\nOptimal z (Maximum Deviation): 0.00023934990167617798\nOptimized Coefficients (Numerator Œ±): [ 2.99729944e-06  0.00000000e+00  3.43310517e-09  3.72730946e-09\n  3.28922199e-09  5.11915460e-09  6.52668076e-09 -3.53255208e-09\n  0.00000000e+00  0.00000000e+00  5.40812879e-08  0.00000000e+00\n  0.00000000e+00  0.00000000e+00 -5.13307886e-09  1.72538473e-08\n  3.45665156e-07  1.92944750e-06  0.00000000e+00  7.17278826e-08\n  0.00000000e+00 -3.75433593e-09 -2.58793422e-09  0.00000000e+00\n  0.00000000e+00  0.00000000e+00  2.00046704e-06  1.36848257e-08\n  0.00000000e+00  0.00000000e+00  2.00008024e-06  5.63482047e-05\n  0.00000000e+00  0.00000000e+00  2.00068700e-06  1.99950146e-06\n  0.00000000e+00  0.00000000e+00  0.00000000e+00  1.98599977e-06\n  1.99742126e-06  1.98869984e-06  0.00000000e+00  1.98325238e-06\n  0.00000000e+00  1.99269236e-06  0.00000000e+00  0.00000000e+00\n  5.11689908e-06  1.39955197e-08  1.98194635e-06  1.99769775e-06\n  0.00000000e+00  1.99963669e-06  1.97985116e-06 -7.46306138e-09\n  1.86566803e-06  1.99836075e-06  1.99418592e-06  5.50591567e-06\n -3.29540980e-08  0.00000000e+00  0.00000000e+00  2.00166679e-06\n  1.98725801e-06  1.97649137e-06  2.00121471e-06  0.00000000e+00\n  0.00000000e+00  1.97371053e-06  0.00000000e+00  2.06556332e-06\n  1.96191226e-06  0.00000000e+00  2.02678324e-06  0.00000000e+00\n -1.68345235e-09  1.99889579e-06]\nOptimized Coefficients (Denominator Œ≤): [ 9.99103475e-07 -2.19071030e-10  1.65847117e-09  5.52154377e-10\n  1.44896580e-09  1.77441088e-09  1.86097025e-09 -4.57838627e-09\n  2.31395785e-09  5.94764648e-09 -3.35139195e-10 -1.03920638e-10\n  5.70425104e-10 -3.46900441e-09  0.00000000e+00  0.00000000e+00\n  0.00000000e+00  0.00000000e+00  1.26066347e-09 -7.98125913e-10\n  4.48962664e-10  0.00000000e+00  4.10794916e-11  5.02121625e-09\n  1.93755404e-08  1.64043271e-08  0.00000000e+00  4.14393390e-09\n  3.25650992e-10  4.65851044e-08  0.00000000e+00  1.35860297e-05\n  2.97134163e-09  1.82120940e-10  8.31135391e-10  0.00000000e+00\n  0.00000000e+00  1.28023548e-06  1.07131093e-06  0.00000000e+00\n  0.00000000e+00 -1.72512087e-09  2.31937739e-07 -5.07754622e-10\n  0.00000000e+00  1.17043887e-10  1.29133722e-09  4.00222059e-10\n  0.00000000e+00  0.00000000e+00  2.74189974e-10  0.00000000e+00\n -2.55730654e-09  0.00000000e+00  0.00000000e+00 -1.94879991e-09\n -1.39214592e-09 -9.63886666e-10 -3.43103656e-09  0.00000000e+00\n -8.30802177e-09 -5.70315034e-10  3.37361098e-09  5.52573884e-10\n  0.00000000e+00  0.00000000e+00  5.14358463e-10  7.62377568e-09\n -1.26952735e-09  0.00000000e+00  8.54398203e-08  0.00000000e+00\n -9.34465539e-09 -7.84812199e-09  7.96365745e-09  5.68805879e-10\n  0.00000000e+00  0.00000000e+00]\nOptimal Œ∏: 9.997082114802247e-07\nModel for digit 1 saved at /kaggle/working/models/\nTraining classifier for digit 2...\nNumber of Iterations: 29\nOptimal z (Maximum Deviation): 9.313225746154785e-07\nOptimized Coefficients (Numerator Œ±): [ 2.99999978e-06  0.00000000e+00 -2.43201601e-12  8.13281167e-12\n  3.21788339e-12  1.09750498e-11 -2.02386363e-11 -6.66502063e-11\n  8.79463877e-12 -6.92202167e-11 -5.59398551e-11  2.18968289e-10\n  4.07265945e-11 -9.30404369e-11 -9.13955448e-10 -1.52765560e-09\n  3.43449510e-09 -2.90365203e-10 -4.45448198e-09  5.78176115e-09\n -1.81916804e-10  3.09322369e-11  5.66780354e-11 -1.22944624e-09\n -2.89988570e-10  1.72680433e-08 -1.68419810e-10 -3.04919727e-11\n  8.07769471e-10 -5.93287568e-09  2.48726538e-10  7.00669188e-09\n  0.00000000e+00  0.00000000e+00  7.98003015e-09 -2.20900077e-08\n  3.73246095e-07  0.00000000e+00  0.00000000e+00 -3.29413970e-08\n  2.00163419e-06 -2.67315903e-12  6.83216996e-10  0.00000000e+00\n  0.00000000e+00  1.99997442e-06  8.17650741e-12 -1.70988064e-11\n -1.29065860e-09  0.00000000e+00  0.00000000e+00  2.00005816e-06\n -3.92557694e-11 -2.17642096e-10  2.47775253e-12 -1.19890326e-10\n  0.00000000e+00  7.59193299e-13  0.00000000e+00  1.40120055e-06\n  1.29446905e-09 -1.04135584e-08  2.00099477e-06 -1.08569635e-12\n  1.99842202e-06 -4.93442588e-10  0.00000000e+00 -4.55031326e-11\n -8.71633217e-13  9.06326044e-12  1.65825549e-06  0.00000000e+00\n  5.42856283e-11  7.10006117e-11 -1.18969486e-10  2.00019299e-06\n  1.99999801e-06  1.04091557e-08]\nOptimized Coefficients (Denominator Œ≤): [ 1.00000000e-06  2.78504252e-14 -7.63335828e-13  1.35004478e-12\n  1.04709102e-12  2.81812466e-12 -3.51613993e-12 -1.61134908e-11\n  2.44925841e-12 -2.59781447e-11 -8.36435610e-11  5.48626945e-11\n -1.16841765e-12 -2.17427154e-11 -3.12200422e-10 -3.08065302e-10\n  1.78373137e-09 -4.59986018e-10 -1.07850713e-09  1.27363411e-09\n -2.42261213e-11  5.11456201e-12  1.31933971e-11 -2.96667425e-10\n -3.95145613e-13  4.06978231e-09  1.46871769e-11 -9.12808516e-12\n  5.19107250e-10 -3.10017965e-09 -1.18011878e-12 -1.91034782e-11\n  6.05465013e-10  0.00000000e+00  1.38343180e-12 -9.03130002e-09\n  9.33199946e-08  7.68807630e-10 -5.74636417e-09  2.44227832e-11\n  4.13881259e-10 -0.00000000e+00  0.00000000e+00  1.40490559e-09\n  4.00540392e-10  2.19732190e-12  2.43719685e-12 -6.37598778e-12\n -1.08752710e-09  3.57022273e-12 -1.68983615e-12  1.03487053e-11\n -0.00000000e+00 -0.00000000e+00  7.67959065e-12 -2.95648814e-11\n  0.00000000e+00  3.52581953e-13  0.00000000e+00  5.69147265e-09\n  3.25453330e-10 -2.61362961e-09  2.52526979e-10  0.00000000e+00\n -3.88016736e-10 -1.58070425e-10 -6.86386413e-14 -1.22410871e-10\n -1.40395353e-12  9.95659081e-13  0.00000000e+00  0.00000000e+00\n  1.35391695e-11  3.52503200e-11  0.00000000e+00  5.88351332e-11\n  1.61438108e-12  2.61183428e-09]\nOptimal Œ∏: 9.999990462580392e-07\nModel for digit 2 saved at /kaggle/working/models/\nTraining classifier for digit 3...\nNumber of Iterations: 29\nOptimal z (Maximum Deviation): 9.313225746154785e-07\nOptimized Coefficients (Numerator Œ±): [ 3.00000673e-06 -3.86405519e-11  0.00000000e+00  0.00000000e+00\n -7.58072590e-11  1.29066857e-10  8.38032229e-11 -1.74614307e-11\n -1.75105813e-10 -1.78287693e-09 -1.12912916e-09  3.20534192e-10\n  6.59447110e-10  5.67438533e-09  3.87928751e-08  8.08174402e-08\n  0.00000000e+00  1.33759144e-09  1.34717908e-07  0.00000000e+00\n -6.60074271e-09  0.00000000e+00 -3.20872873e-08  3.90712130e-09\n  0.00000000e+00 -2.07787807e-09  1.16524865e-10 -5.54798116e-10\n  3.36498525e-09  0.00000000e+00  1.99954916e-06  0.00000000e+00\n -1.47169969e-08 -1.58461739e-10  2.00002352e-06  3.78449495e-07\n  1.99991382e-06  0.00000000e+00  0.00000000e+00  1.87712784e-10\n  0.00000000e+00  4.40324905e-07 -7.67242470e-08  0.00000000e+00\n  0.00000000e+00  0.00000000e+00 -1.98093891e-09  8.81202764e-12\n -5.83544691e-08  1.99593926e-06  1.99921296e-06  1.99939830e-06\n -6.80362023e-10  0.00000000e+00  7.40671559e-11  2.00000541e-06\n  1.99984508e-06  0.00000000e+00  0.00000000e+00  2.29864725e-09\n -8.77939924e-10  2.49072751e-06  1.99889135e-06  8.25289171e-06\n  1.08289415e-06  0.00000000e+00 -0.00000000e+00  6.10326764e-11\n -5.46838820e-08  1.99740581e-06  2.00001069e-06  0.00000000e+00\n  2.15745635e-06  1.83961120e-06  1.99989197e-06 -7.34501834e-08\n  0.00000000e+00  1.32083563e-07]\nOptimized Coefficients (Denominator Œ≤): [ 1.00000406e-06 -1.31985161e-11 -2.21948393e-13  1.53664944e-12\n -1.52579119e-11 -7.53960510e-11 -3.22430690e-11  2.01782994e-11\n -8.79891943e-12  2.82261018e-10  2.57738192e-10  1.80379071e-10\n  1.75110358e-10  1.38451183e-09  1.09483137e-08  1.99588889e-08\n  2.20061606e-12  3.78788157e-10 -1.69282580e-09  5.35301861e-10\n -2.08356112e-09  5.42704423e-12 -8.01194123e-09 -6.37324954e-10\n  1.06440931e-08  0.00000000e+00  7.25387778e-11 -3.02291882e-09\n -3.11018473e-09 -8.22042005e-09 -0.00000000e+00 -8.55851411e-10\n -1.01289859e-08  5.02126886e-11  2.34203181e-12  1.03871343e-08\n  4.21318831e-11  2.92089100e-08  1.01265313e-09 -4.11885771e-10\n  3.32703565e-11  1.12185669e-07 -2.11844813e-10  2.35568065e-10\n  0.00000000e+00  0.00000000e+00 -4.77999454e-10 -0.00000000e+00\n -2.92352365e-08  8.13316846e-10 -1.64587879e-11 -0.00000000e+00\n -2.01048757e-10 -1.62264147e-10 -8.46941635e-12  0.00000000e+00\n  0.00000000e+00  6.49071336e-12 -2.51626106e-12  0.00000000e+00\n -2.59030513e-10  1.21904268e-07  9.84888090e-12  2.06322265e-06\n  4.16862369e-09  2.07039451e-09  1.42600445e-13 -6.42541435e-12\n  4.51098264e-11 -2.37658095e-11  0.00000000e+00  1.14394490e-06\n  3.93730212e-08  9.20816565e-07  1.22854890e-11  0.00000000e+00\n  8.39389912e-11  3.38085690e-08]\nOptimal Œ∏: 9.999978520900589e-07\nModel for digit 3 saved at /kaggle/working/models/\nTraining classifier for digit 4...\nNumber of Iterations: 29\nOptimal z (Maximum Deviation): 9.313225746154785e-07\nOptimized Coefficients (Numerator Œ±): [ 2.99994892e-06  1.05021176e-10 -6.86674505e-11  4.57306851e-10\n -3.66918479e-10  4.99540450e-11  1.23651236e-09 -2.37934631e-09\n -1.96875586e-09 -8.03206351e-09 -8.04994234e-10  3.04613863e-09\n  1.96923931e-11 -1.05479829e-08  7.90994439e-09 -4.22022035e-09\n  5.49588033e-08 -2.06829237e-08 -1.10885332e-09 -8.75643785e-09\n  4.36613450e-09  0.00000000e+00 -7.79628974e-08  1.94390824e-08\n  7.62077751e-07  1.99877220e-06  3.05758893e-08  1.45727797e-08\n  2.79880186e-06  0.00000000e+00 -1.35662359e-09  1.34630011e-09\n  3.01926824e-08  0.00000000e+00  7.75128825e-10  0.00000000e+00\n  3.04878604e-09  1.27944845e-06  0.00000000e+00  9.99136076e-09\n  2.41537073e-08  1.99983319e-06  0.00000000e+00  1.11125763e-06\n  0.00000000e+00 -1.03397109e-09  0.00000000e+00  1.11762563e-08\n  2.70316812e-08  6.11394331e-08 -2.19858830e-10 -1.12236664e-09\n  1.45169424e-03  0.00000000e+00 -4.29099119e-10  5.47540013e-07\n -3.89871546e-11  1.99963761e-06 -4.69752727e-09  1.95004699e-06\n  3.20714495e-04  1.99936487e-06  2.00003578e-06  3.25090564e-06\n  1.99931272e-06  0.00000000e+00  1.05726697e-10  0.00000000e+00\n  0.00000000e+00 -2.26010180e-09 -0.00000000e+00  0.00000000e+00\n  1.61515972e-08  7.97952881e-03  0.00000000e+00 -9.21526500e-08\n  1.99995619e-06  0.00000000e+00]\nOptimized Coefficients (Denominator Œ≤): [ 1.00000550e-06  1.16752622e-12 -8.48677522e-11  2.79147396e-11\n -7.73335036e-11  8.20361307e-12  3.12407029e-10 -2.28967801e-10\n -6.33228082e-10 -1.32700378e-09 -1.05351532e-10  2.60112482e-10\n  6.08401726e-11 -9.62461042e-10  1.58075461e-09  7.17069827e-10\n  1.63406941e-12  1.02517827e-09  2.03327026e-10  7.79790041e-10\n  2.33508592e-09  4.24459935e-11 -3.26827507e-08  5.99638480e-09\n -2.24806072e-10 -2.13126987e-10  5.01489921e-11  0.00000000e+00\n  1.99829759e-07  4.07965919e-08 -7.28244854e-11  1.46634154e-09\n -2.71667900e-09 -5.21233413e-08  3.22462233e-10  4.01718158e-09\n  7.04555671e-10 -1.34242423e-08  1.85101184e-08  8.48424106e-10\n  6.06971837e-09 -0.00000000e+00 -2.56588676e-09 -1.14757288e-09\n  0.00000000e+00 -3.37147497e-11 -4.88396732e-11 -0.00000000e+00\n  1.34111248e-08  1.82244047e-08  1.11957697e-11 -5.41989668e-10\n  3.62924105e-04  2.93002045e-09 -1.06122278e-10 -0.00000000e+00\n -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -2.00044788e-08\n  7.96864338e-05  0.00000000e+00 -3.53301518e-11  8.12733448e-07\n -0.00000000e+00  1.47347491e-08  3.35126208e-11  1.52382303e-08\n  0.00000000e+00  0.00000000e+00  0.00000000e+00  1.90617606e-07\n  4.27919064e-09  1.99483751e-03  3.29802019e-09  1.52477043e-12\n -0.00000000e+00 -6.61382042e-11]\nOptimal Œ∏: 9.999928952037702e-07\nModel for digit 4 saved at /kaggle/working/models/\nTraining classifier for digit 5...\nNumber of Iterations: 29\nOptimal z (Maximum Deviation): 9.313225746154785e-07\nOptimized Coefficients (Numerator Œ±): [ 2.99999856e-06  0.00000000e+00 -5.96581975e-12 -1.48391992e-12\n  1.60246491e-11  1.00775241e-11 -1.55531673e-11  2.05497142e-11\n  1.66441052e-11 -5.72215933e-10  6.70111845e-10 -6.12934615e-11\n -1.94230679e-09 -9.18785012e-12  3.48328876e-08  0.00000000e+00\n  8.16802805e-09  9.08352116e-10 -2.83447859e-12  2.43178817e-09\n  0.00000000e+00  1.39265911e-09  1.75491023e-08  3.68914818e-09\n -4.41486531e-09  1.26809262e-08  3.86898069e-11 -1.31130604e-08\n  1.76037664e-09 -1.13122727e-08  2.00000237e-06  1.29419717e-10\n -2.51645756e-12  7.07089706e-09  0.00000000e+00 -7.22658826e-08\n -1.56082983e-09  2.65321368e-08 -7.04188668e-08  3.55354058e-09\n  6.69475741e-08  2.79314386e-08 -4.82126718e-10 -3.03258850e-10\n  0.00000000e+00  0.00000000e+00 -6.75141978e-10  1.02436024e-11\n -2.65589701e-08  2.00822825e-06  2.00002162e-06  0.00000000e+00\n  1.86001758e-09  2.00085238e-06 -3.31872630e-11 -4.95214477e-09\n  4.28870794e-07  0.00000000e+00  1.99990746e-06  6.03599602e-09\n -7.89851191e-11 -3.22747578e-08  2.05184344e-09 -4.67766746e-11\n -2.03340200e-09 -7.93564908e-10  1.99690462e-06 -4.34347689e-10\n  1.94398812e-06 -7.41765657e-10 -1.14363609e-08  0.00000000e+00\n  2.99779240e-10 -5.55753915e-09 -3.25674209e-09  0.00000000e+00\n  1.99970701e-06  3.10832563e-08]\nOptimized Coefficients (Denominator Œ≤): [ 1.00000007e-06  4.23868023e-13  0.00000000e+00 -1.45722248e-12\n  9.86527135e-13 -1.75631389e-12  4.02461527e-13 -1.28847688e-12\n  3.11746636e-12 -9.41157633e-13  1.02530669e-12  4.23786223e-12\n -4.52578767e-11 -2.46024790e-13  4.44575495e-10  1.67577116e-11\n  2.08746835e-09 -1.01193429e-11 -9.22892335e-12  1.49741654e-12\n -5.61464306e-12 -1.11641155e-12 -2.42080543e-12 -2.36495697e-09\n -1.18192013e-10  3.71786682e-09  1.22402297e-11 -1.41273689e-11\n  8.84637874e-10 -6.11843599e-10  7.28206794e-13  0.00000000e+00\n -4.72941180e-12  1.77584788e-09 -1.43951357e-09 -1.01944363e-09\n -1.12511612e-11  4.54202689e-10 -2.52079453e-08 -4.20150269e-10\n -1.14102205e-13 -1.15695216e-11  1.09151423e-11  7.81359333e-12\n  7.38957211e-08 -2.99761263e-10 -1.72241817e-10  1.73842503e-12\n -4.48027536e-10 -2.59185332e-12  7.53836869e-14  8.96435066e-11\n  5.24598964e-11  1.98708657e-10  7.48411436e-13 -2.47831413e-09\n  0.00000000e+00 -3.19856459e-09 -3.63487252e-12  2.52103865e-08\n -1.17459315e-11  1.34046802e-10  3.50955856e-09 -1.13954891e-11\n -9.90282255e-10 -1.57115904e-10 -7.73141308e-10 -1.04185778e-10\n  6.22075302e-11  9.88375458e-11  0.00000000e+00 -1.06892946e-08\n  7.38273842e-11 -8.40632020e-10 -1.24653300e-10  9.99438435e-07\n  4.27042194e-13 -4.34546257e-10]\nOptimal Œ∏: 9.999987271619752e-07\nModel for digit 5 saved at /kaggle/working/models/\nTraining classifier for digit 6...\nNumber of Iterations: 29\nOptimal z (Maximum Deviation): 9.313225746154785e-07\nOptimized Coefficients (Numerator Œ±): [ 2.99989870e-06 -7.62820370e-12  0.00000000e+00  1.41193083e-10\n  3.79410429e-11  7.02457658e-10 -3.35881979e-10  2.07200199e-09\n -5.72805833e-10  2.02588333e-09 -1.52245275e-10  1.72855057e-08\n -7.29945948e-09  2.69447785e-08  8.11666223e-08  2.03437969e-07\n -2.97047282e-10  9.79860836e-10 -5.75578546e-10  1.42255259e-10\n  1.14495585e-10  9.42438993e-07 -5.19996822e-11 -1.81171528e-10\n -1.13250826e-08  0.00000000e+00 -3.05211471e-08  0.00000000e+00\n  1.74832517e-09  5.70467410e-08 -5.10187387e-10  4.28352556e-09\n -1.66784797e-09  2.65908276e-09 -1.83875101e-10 -8.05039978e-08\n  1.99996921e-06  2.01799102e-06  0.00000000e+00  1.97264018e-06\n -1.00908816e-08 -8.41732487e-09  1.99906926e-06 -8.99413448e-09\n -2.92783738e-09  2.00500509e-06  5.66567781e-07  1.99981717e-06\n -1.83282706e-08  1.53228656e-08  2.00131271e-06  0.00000000e+00\n  3.69275592e-09  2.13135660e-10  4.41864756e-05  1.99757147e-06\n  1.99582335e-06  1.99991017e-06 -5.54246113e-09  1.48476181e-06\n -3.81972658e-10  2.06283819e-06 -2.85119026e-10  1.02054814e-10\n  1.99983663e-06 -1.68896392e-08 -2.66305877e-10  0.00000000e+00\n  1.99940666e-06  2.00026850e-06  2.00156018e-06  0.00000000e+00\n  2.00008255e-06  0.00000000e+00  1.99943887e-06  0.00000000e+00\n  1.99976364e-06 -7.18325111e-08]\nOptimized Coefficients (Denominator Œ≤): [ 9.99937370e-07  2.68598750e-11 -2.28738127e-11  1.08519954e-10\n  9.19803883e-11 -2.34965358e-10  2.30741046e-11  6.26735031e-10\n -3.03198281e-10  2.94648374e-10 -7.18969781e-11  8.62359124e-09\n -1.60110955e-09  7.55002024e-09  2.02937667e-08  5.33627848e-08\n -7.00179093e-11  2.54055663e-10 -1.14446401e-10  1.32092757e-10\n  1.12220119e-10 -1.14098505e-10  1.45278805e-11 -4.62769925e-10\n -1.55742903e-11 -5.21537768e-12 -7.96611077e-09 -3.40042390e-10\n  4.90843741e-10 -1.45230786e-11  2.65116771e-11 -3.94099495e-10\n -4.22413190e-10  8.07741108e-10 -6.45187919e-11 -1.64429552e-09\n -4.42730806e-12  4.56097969e-09  3.83500685e-07 -7.69883280e-09\n -2.45057455e-09  1.17637958e-10 -1.34933594e-10 -2.89247999e-13\n -9.62170167e-10  1.10639232e-09  1.41657770e-07 -9.26037901e-11\n -4.72546794e-09  7.92141719e-09 -5.15267009e-11 -1.73055722e-11\n  1.54666830e-09  8.34876161e-13  1.05465984e-05 -5.91159960e-10\n  4.89264030e-11  8.42371114e-12  1.28953777e-11  0.00000000e+00\n -3.48746541e-13 -5.66524555e-10  0.00000000e+00  5.57976830e-11\n -1.71765632e-11  6.67350123e-11  1.85513204e-11  8.07159042e-09\n -2.38256716e-10  6.50923200e-11  4.52869247e-10  0.00000000e+00\n  1.27344618e-11  4.31349264e-10 -7.92481259e-11  1.89397080e-08\n -1.99186923e-11  6.18193438e-10]\nOptimal Œ∏: 9.999920340220737e-07\nModel for digit 6 saved at /kaggle/working/models/\nTraining classifier for digit 7...\nNumber of Iterations: 29\nOptimal z (Maximum Deviation): 0.0009546056389808655\nOptimized Coefficients (Numerator Œ±): [ 3.00000946e-06 -1.34424722e-13 -6.65375621e-12  0.00000000e+00\n -3.96134765e-11  4.94947405e-11 -2.31614743e-11  1.24005076e-10\n  7.41833596e-11 -3.34058462e-09 -1.25603731e-08 -1.61234479e-09\n  2.62514307e-09 -4.38997940e-10  5.00732279e-09 -9.41812456e-09\n  0.00000000e+00  8.76024350e-09 -1.04051269e-09  0.00000000e+00\n -2.29357147e-09 -1.37854135e-09  6.87184328e-09  1.12452841e-07\n -2.95651437e-08  0.00000000e+00 -1.07297111e-09 -1.29887587e-08\n -1.60512709e-09  3.17717524e-09  0.00000000e+00  7.77407839e-07\n  0.00000000e+00 -4.90148405e-09  0.00000000e+00  0.00000000e+00\n -2.29991344e-09  2.55928107e-09 -9.86509490e-09  2.00222205e-06\n  3.48963551e-05  0.00000000e+00 -3.65026291e-09  1.99053343e-06\n  0.00000000e+00  0.00000000e+00  2.00001779e-06  2.00002268e-06\n -2.13851589e-09 -1.26349104e-08  1.63246369e-03  6.33994533e-10\n  1.01151326e-06  2.00005534e-06  6.73916907e-10  1.99138333e-06\n  2.00000191e-06  0.00000000e+00 -2.16431700e-09  1.21826818e-08\n  0.00000000e+00  1.99079586e-06  1.98777149e-06 -1.69976095e-09\n  1.21928610e-11 -1.60889946e-08  0.00000000e+00  0.00000000e+00\n  4.76561999e-10  0.00000000e+00  1.65825246e-06  2.03158876e-06\n  1.99905649e-06  3.04738747e-07  2.00136654e-06 -7.30757404e-08\n  1.99999847e-06  0.00000000e+00]\nOptimized Coefficients (Denominator Œ≤): [ 1.00000245e-06 -5.37438675e-12 -2.21431422e-12  2.12995543e-11\n -7.39996389e-11  2.56377008e-11  4.78440911e-12  8.01558227e-11\n  5.04221266e-11 -7.28179470e-10 -3.15688304e-09 -5.39127122e-10\n  1.44273427e-10  4.60741443e-10  1.41403792e-09 -3.49063891e-09\n -3.27731242e-12 -1.10215767e-10 -5.04680091e-10 -1.98529952e-12\n -7.02868046e-10  2.11167514e-11  1.55620460e-09  5.84017562e-08\n -3.46283560e-12 -6.32082335e-09 -9.02809249e-11 -3.07699883e-09\n -3.99881129e-10  0.00000000e+00 -2.16966342e-11  1.94312307e-07\n  1.68727083e-11 -1.24686081e-09  4.82308988e-12  1.04121590e-10\n  0.00000000e+00  3.76210793e-11 -1.59828874e-09 -8.37515586e-12\n  8.22213248e-06 -5.45764637e-11  2.85995792e-10 -2.34129074e-09\n -6.64627216e-11  3.09616393e-10 -3.46177373e-11  6.42984243e-12\n  0.00000000e+00  2.08360536e-09  4.08213338e-04  1.91714320e-10\n -3.17500182e-10 -8.98255340e-11  1.75879095e-10 -2.24567454e-11\n -7.69859997e-12  3.18666871e-11 -8.63081865e-11  4.72315777e-09\n -5.92502592e-12 -1.22683803e-09 -6.87908869e-11 -8.38134515e-10\n  0.00000000e+00  3.26719868e-10 -4.71279374e-08  0.00000000e+00\n -8.04906851e-11 -0.00000000e+00  0.00000000e+00  0.00000000e+00\n -2.33374958e-10  0.00000000e+00  3.64538618e-10  9.90967885e-11\n  0.00000000e+00  1.24966676e-09]\nOptimal Œ∏: 9.990439092903212e-07\nModel for digit 7 saved at /kaggle/working/models/\nTraining classifier for digit 8...\nNumber of Iterations: 29\nOptimal z (Maximum Deviation): 1.955777406692505e-05\nOptimized Coefficients (Numerator Œ±): [ 3.00919763e-06 -1.52808707e-08 -1.53312229e-08 -1.25615396e-08\n  0.00000000e+00  0.00000000e+00  0.00000000e+00 -5.52043993e-08\n -9.08759096e-09  1.23555829e-06  4.27249038e-07 -3.31511780e-08\n  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n  0.00000000e+00  2.00829270e-06  0.00000000e+00  0.00000000e+00\n  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n  0.00000000e+00  0.00000000e+00  2.74418200e-06  0.00000000e+00\n  0.00000000e+00  0.00000000e+00  2.09995058e-07  6.84650836e-07\n  0.00000000e+00  1.46844523e-08  1.97828805e-06  2.01727381e-06\n  2.00729428e-06  1.97981010e-06  2.21317732e-05  0.00000000e+00\n  0.00000000e+00  1.99873249e-06  1.04762232e-06  2.00140877e-06\n  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n -1.53439272e-09  0.00000000e+00  0.00000000e+00  2.00765922e-06\n  0.00000000e+00  0.00000000e+00  0.00000000e+00  2.00315639e-06\n  0.00000000e+00  1.99836829e-06  2.00521526e-06  0.00000000e+00\n  3.50237910e-09  0.00000000e+00  0.00000000e+00  0.00000000e+00\n  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n  0.00000000e+00 -5.90893338e-09  1.20631272e-07  0.00000000e+00\n  5.91825701e-09  1.99624327e-06]\nOptimized Coefficients (Denominator Œ≤): [ 1.00176270e-06 -5.23099540e-09 -1.39573254e-09  2.31260142e-10\n -3.70948771e-10  7.72107117e-09 -8.65536470e-09 -1.01629778e-08\n -1.25826291e-08  1.73138752e-07  1.04547276e-07 -9.43716495e-10\n -3.86965137e-08 -4.80085341e-09  6.35484560e-10  6.39046035e-09\n -4.88233596e-10  0.00000000e+00  2.52682494e-09  0.00000000e+00\n  7.36192516e-11  5.07654331e-10  2.40327624e-09 -1.33914305e-09\n -4.92192281e-10 -2.27469413e-09  6.87818760e-07  9.34859541e-10\n  1.48762390e-09  5.34267200e-08  0.00000000e+00  0.00000000e+00\n  5.25344723e-09  4.27799655e-10 -5.84724935e-09  0.00000000e+00\n  0.00000000e+00 -5.67213719e-09  0.00000000e+00  9.27986710e-09\n  4.77063651e-09  0.00000000e+00  0.00000000e+00  0.00000000e+00\n -1.59345932e-09  2.89291140e-08  6.92287401e-10  0.00000000e+00\n  0.00000000e+00  1.96043921e-09 -9.81737083e-10  1.52676227e-09\n  3.80901532e-08 -4.28661349e-10  2.22079068e-09  0.00000000e+00\n  3.31326728e-08  0.00000000e+00  2.32325932e-09  5.58871239e-06\n  0.00000000e+00  0.00000000e+00 -7.16615116e-10  0.00000000e+00\n -2.48383902e-10  1.10643877e-08 -4.83645725e-10  9.96776097e-07\n -1.69073139e-09  1.50712937e-10  0.00000000e+00  0.00000000e+00\n  2.88254439e-09  0.00000000e+00  2.89492981e-08 -1.75123230e-09\n  0.00000000e+00  0.00000000e+00]\nOptimal Œ∏: 9.997993557532605e-07\nModel for digit 8 saved at /kaggle/working/models/\nTraining classifier for digit 9...\nNumber of Iterations: 29\nOptimal z (Maximum Deviation): 9.313225746154785e-07\nOptimized Coefficients (Numerator Œ±): [ 2.99997242e-06 -2.47696459e-11  3.68427498e-11 -2.22881959e-11\n  1.87639240e-10  4.39724172e-10  1.38206822e-10  2.48751023e-10\n  1.92381458e-10  1.57753259e-09  6.16553546e-09 -4.99000058e-10\n  2.86738881e-10 -4.90525574e-09 -1.18822874e-08  0.00000000e+00\n  3.25208840e-09  2.93908696e-08  0.00000000e+00 -7.94777175e-10\n -4.38359591e-10  1.99208886e-06 -1.19679598e-09  0.00000000e+00\n  0.00000000e+00  0.00000000e+00  6.21579038e-10 -2.24247753e-08\n  1.09448607e-08  0.00000000e+00 -4.92953531e-10  1.99111409e-06\n -5.77137632e-11  0.00000000e+00 -2.76782744e-11 -1.44034022e-08\n  1.97664741e-06 -3.47274143e-10  8.16608430e-04  1.14873991e-05\n -1.14250436e-09  4.04839251e-06  2.14569213e-08  1.20374808e-08\n  0.00000000e+00  1.99804408e-06 -2.16900558e-09 -1.30680808e-08\n  2.87738703e-11  3.10862209e-06  1.38918437e-11  2.00013083e-06\n  1.99971577e-06  1.99999613e-06 -5.25662589e-10 -9.69917541e-09\n  9.51968465e-08 -7.64091824e-11 -1.94932852e-09  2.03784220e-02\n  2.00037600e-06  0.00000000e+00 -1.11207740e-08  0.00000000e+00\n  0.00000000e+00  1.99108241e-06 -4.64335115e-10  0.00000000e+00\n  0.00000000e+00  1.99891182e-06  1.99975363e-06  1.59035924e-06\n -7.34949084e-12  2.10272840e-06 -1.24918655e-09  1.99972132e-06\n  0.00000000e+00  1.99993933e-06]\nOptimized Coefficients (Denominator Œ≤): [ 1.00000418e-06 -1.02197555e-11 -6.67126656e-12 -2.49350286e-12\n  3.50379130e-11  4.27360383e-11 -6.14580250e-11 -2.30255246e-11\n -2.66034709e-11  2.48516362e-11 -4.32921666e-11 -5.03360366e-10\n  1.94639783e-10 -1.65900204e-09 -2.89886979e-09  8.10428512e-11\n  8.23532129e-10 -3.33690274e-09  1.03277099e-09 -5.56933965e-12\n -2.54856017e-12 -1.61450988e-09 -2.90221890e-11  1.09113413e-11\n -0.00000000e+00 -2.49140310e-11  1.92464426e-10 -2.71492361e-09\n  7.30385802e-13  1.41792824e-09 -1.94663322e-13  5.00683826e-07\n  4.12210808e-11  5.80329095e-09  0.00000000e+00  0.00000000e+00\n  6.34368721e-12  8.08542869e-12  2.03629428e-04  2.37232939e-06\n  3.70003862e-10  5.12148639e-07  1.05911577e-08 -4.10352604e-11\n -3.55706140e-08 -5.24755243e-10 -1.12871777e-09 -3.26365161e-09\n  0.00000000e+00  2.75374803e-07  6.70550551e-13  1.32653910e-11\n -1.66855103e-10 -3.09173197e-13  2.61944094e-11 -2.41624346e-09\n  2.38003202e-08 -6.04639237e-12  0.00000000e+00  5.09460622e-03\n  6.23836958e-11 -1.30847855e-11  4.54921887e-10 -4.28518615e-12\n  0.00000000e+00  0.00000000e+00 -4.25935470e-12  0.00000000e+00\n -7.66404822e-09 -2.15027580e-10 -5.75843812e-11  0.00000000e+00\n  8.73219415e-12  2.31761525e-08 -2.28040027e-11  0.00000000e+00\n  9.97500421e-07  1.10208210e-11]\nOptimal Œ∏: 9.999975198654226e-07\nModel for digit 9 saved at /kaggle/working/models/\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"### [Testing]","metadata":{}},{"cell_type":"code","source":"import cupy as cp\nimport numpy as np\nfrom sklearn.decomposition import PCA\nimport pickle\nimport matplotlib.pyplot as plt\n\n# Define the rational function\n# (Œ±_0 + Œ±_1*x1**1 + Œ±_2*x2**2 + ...)\ndef rational_function(x, alpha, beta):\n    numerator = alpha[0] + sum(alpha[i+1] * x[i] ** (i + 1) for i in range(len(x)))\n    denominator = beta[0] + sum(beta[i+1] * x[i] ** (i + 1) for i in range(len(x)))\n    return numerator / denominator\n\n#-----------------------------------------------------\n# import itertools\n\n# def generate_multi_indices(n, d):\n#     indices = [idx for idx in itertools.product(range(d + 1), repeat=n) if sum(idx) <= d]\n#     return indices\n\n# def construct_polynomial(x, coefficients, indices):\n#     polynomial_value = 0\n#     for coeff, idx in zip(coefficients, indices):\n#         term = coeff * np.prod([x[i] ** idx[i] for i in range(len(x))])\n#         polynomial_value += term\n#     return polynomial_value\n\n# def rational_function(x, alpha, beta, n, d):\n#     indices = generate_multi_indices(n, d)\n\n#     # Compute numerator and denominator\n#     numerator = construct_polynomial(x, alpha, indices)\n#     denominator = construct_polynomial(x, beta, indices)\n\n#     # # Avoid division by zero\n#     # if np.abs(denominator) < 1e-8:\n#     #     denominator = 1e-8\n\n#     return numerator / denominator\n\n#-----------------------------------------------------\n# Import\nfrom keras.datasets import mnist\n(_, _), (x_test, y_test) = mnist.load_data()\nprint(f\"x_test shape: {x_test.shape}, y_test shape: {y_test.shape}\")\n\n#1 Flatten\nx_test = x_test.reshape(x_test.shape[0], -1)\nprint(f\"x_test shape: {x_test.shape}, y_test shape: {y_test.shape}\")\n\n#2 Subsets\nsubset_size = 10000\nx_test_subset = x_test[:subset_size]\ny_test_subset = y_test[:subset_size]\nprint(f\"x_test_subset shape: {x_test_subset.shape}\")\n\n#3 PCA\nfrom sklearn.decomposition import PCA\nimport pickle\nn_components = 77\npca = PCA(n_components=n_components)\nx_test_pca = pca.fit_transform(x_test_subset)\nprint(f\"x_test_pca shape: \", x_test_pca.shape)\n\n#4 Normalize\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler(feature_range=(0, 1))\nx_test_norm = scaler.fit_transform(x_test_pca)\nprint(f\"x_test_norm shape: {x_test_norm.shape}\")\n\n#------------------------------------------\n# Load the saved models and test\nmodels_dir = \"/kaggle/working/models/\"\naccuracies = []\n\n#------------------------------------------\nfor digit in range(10):\n    # Load model for each digit\n    with open(f\"{models_dir}classifier_{digit}.pkl\", \"rb\") as file:\n        model = pickle.load(file)\n\n    alpha = model[\"alpha\"]\n    beta = model[\"beta\"]\n    theta = model[\"theta\"]\n\n    # n = 2\n    # d = 2\n    # # Evaluate the rational function for each test data point\n    # y_predicted = [\n    #     rational_function(x, alpha, beta, n, d) for x in x_test_norm\n    # ]\n\n    y_predicted = [\n    rational_function(x, alpha, beta) for x in x_test_norm\n    ]\n\n    # Convert predictions to binary (higher digit - for this digit, 0/lower digit for others)\n    y_pred_binary = np.array(y_predicted) < 3\n    y_true_binary = y_test_subset == digit\n\n    # Calculate accuracy for this digit\n    accuracy = np.mean(y_pred_binary == y_true_binary)\n    accuracies.append(accuracy)\n\n    print(f\"Accuracy for digit {digit}: {accuracy*100:.2f}%\")\n\n#------------------------------------------\n# Calculate and print overall accuracy\noverall_accuracy = np.mean(accuracies)\nprint(f\"Overall Accuracy: {overall_accuracy*100:.2f}%\")\n\n#------------------------------------------\n# Plotting accuracies for each digit\nplt.bar(range(10), accuracies, color='blue', alpha=0.7, label=\"Accuracy\")\nplt.xlabel(\"Digits\")\nplt.ylabel(\"Accuracy (%)\")\nplt.title(\"Accuracy for Each Digit\")\nplt.xticks(range(10))\nplt.ylim(0, 1)\nplt.legend()\nplt.grid(True)\nplt.show()\n\n# print(f\"y_pred_binary =\", y_pred_binary)\n# print(f\"y_true_binary =\", y_true_binary)\n\n# print(f\"y_pred_binary.shape =\", y_pred_binary.shape)\n# print(f\"y_true_binary.shape =\", y_true_binary.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T23:40:48.641010Z","iopub.execute_input":"2025-01-07T23:40:48.641848Z","iopub.status.idle":"2025-01-07T23:40:57.620346Z","shell.execute_reply.started":"2025-01-07T23:40:48.641811Z","shell.execute_reply":"2025-01-07T23:40:57.619498Z"}},"outputs":[{"name":"stdout","text":"x_test shape: (10000, 28, 28), y_test shape: (10000,)\nx_test shape: (10000, 784), y_test shape: (10000,)\nx_test_subset shape: (10000, 784)\nx_test_pca shape:  (10000, 77)\nx_test_norm shape: (10000, 77)\nAccuracy for digit 0: 60.99%\nAccuracy for digit 1: 78.34%\nAccuracy for digit 2: 54.61%\nAccuracy for digit 3: 66.39%\nAccuracy for digit 4: 64.87%\nAccuracy for digit 5: 66.75%\nAccuracy for digit 6: 87.01%\nAccuracy for digit 7: 51.38%\nAccuracy for digit 8: 67.12%\nAccuracy for digit 9: 82.60%\nOverall Accuracy: 68.01%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}],"execution_count":11}]}